From fb8ffd68343e682faa2d12bfb2131732e7c12e90 Mon Sep 17 00:00:00 2001
From: Liu Zixian <liuzixian4@huawei.com>
Date: Fri, 17 Sep 2021 15:10:57 +0000
Subject: [PATCH 1/4] add CONFIG and vm_real_file

Signed-off-by: Liu Zixian <liuzixian4@huawei.com>
---
 fs/proc/task_mmu.c                     |  8 +++-
 include/linux/hugetlb_inline.h         | 14 +++++++
 include/linux/mm.h                     |  9 ++++
 include/linux/mm_types.h               |  4 +-
 include/uapi/asm-generic/mman-common.h |  3 ++
 kernel/events/core.c                   | 12 ++++++
 kernel/fork.c                          |  5 +++
 lib/Kconfig.euleros                    | 10 +++++
 mm/hugetlb.c                           |  6 +++
 mm/mmap.c                              | 58 ++++++++++++++++++++++++++
 mm/util.c                              | 18 ++++++++
 11 files changed, 145 insertions(+), 2 deletions(-)

diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
index 3e90467bb..b09933666 100644
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@ -323,7 +323,13 @@ show_map_vma(struct seq_file *m, struct vm_area_struct *vma, int is_pid)
 	 */
 	if (file) {
 		seq_pad(m, ' ');
-		seq_file_path(m, file, "\n");
+
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+		if (is_vm_exec_hugepages(vma) && vma->vm_real_file)
+			seq_file_path(m, vma->vm_real_file, "\n");
+		else
+#endif
+			seq_file_path(m, file, "\n");
 		goto done;
 	}
 
diff --git a/include/linux/hugetlb_inline.h b/include/linux/hugetlb_inline.h
index 0660a03d3..ea9ad69b3 100644
--- a/include/linux/hugetlb_inline.h
+++ b/include/linux/hugetlb_inline.h
@@ -11,6 +11,13 @@ static inline bool is_vm_hugetlb_page(struct vm_area_struct *vma)
 	return !!(vma->vm_flags & VM_HUGETLB);
 }
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+static inline bool is_vm_exec_hugepages(struct vm_area_struct *vma)
+{
+	return !!(vma->vm_flags & VM_EXEC_HUGEPAGES);
+}
+#endif
+
 #else
 
 static inline bool is_vm_hugetlb_page(struct vm_area_struct *vma)
@@ -18,6 +25,13 @@ static inline bool is_vm_hugetlb_page(struct vm_area_struct *vma)
 	return false;
 }
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+static inline bool is_vm_exec_hugepages(struct vm_area_struct *vma)
+{
+	return false;
+}
+#endif
+
 #endif
 
 #endif
diff --git a/include/linux/mm.h b/include/linux/mm.h
index 05f4a07f4..adb17657b 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -238,6 +238,9 @@ extern unsigned int kobjsize(const void *objp);
  */
 #define VM_NOCLEAR      0x00000001      /* No clear page in __do_huge_pmd_anonymous_page for vfio */
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+#define VM_EXEC_HUGEPAGES	0x2000000000000000 /* hugetlb with fallback and vm_real_file */
+#endif
 #ifdef CONFIG_EULEROS_EVMM_TLB
 #define VM_EVMM_TLB 0x4000000000000000 /* evmm pgtable entry(1G + 2M + 4K mixed type) flag */
 #endif
@@ -2395,6 +2398,12 @@ extern int vm_munmap(unsigned long, size_t);
 extern unsigned long __must_check vm_mmap(struct file *, unsigned long,
         unsigned long, unsigned long,
         unsigned long, unsigned long);
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+extern unsigned long __must_check vm_mmap_hugepage(struct file *, unsigned long,
+        unsigned long, unsigned long,
+        unsigned long, unsigned long);
+extern void read_real_file(struct page *page, struct vm_area_struct *vma, loff_t *off);
+#endif
 
 struct vm_unmapped_area_info {
 #define VM_UNMAPPED_AREA_TOPDOWN 1
diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 023a82774..e0672c9ee 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -325,7 +325,9 @@ struct vm_area_struct {
 	struct vm_userfaultfd_ctx vm_userfaultfd_ctx;
 
 	RH_KABI_USE(1, unsigned long vm_flags2)
-	RH_KABI_RESERVE(2)
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+	RH_KABI_USE(2, struct file *vm_real_file)
+#endif
 	RH_KABI_RESERVE(3)
 	RH_KABI_RESERVE(4)
 } __randomize_layout;
diff --git a/include/uapi/asm-generic/mman-common.h b/include/uapi/asm-generic/mman-common.h
index e7ee32861..6c413193f 100644
--- a/include/uapi/asm-generic/mman-common.h
+++ b/include/uapi/asm-generic/mman-common.h
@@ -29,6 +29,9 @@
 
 /* 0x0100 - 0x80000 flags are defined in asm-generic/mman.h */
 #define MAP_FIXED_NOREPLACE	0x100000	/* MAP_FIXED which doesn't unmap underlying mapping */
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+#define MAP_EXEC_HUGEPAGES	0x200000	/* MAP_HUGETLB with fallback and vm_real_file */
+#endif
 
 /*
  * Flags for mlock
diff --git a/kernel/events/core.c b/kernel/events/core.c
index 119a74fff..db86c8752 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -7464,6 +7464,14 @@ static void perf_event_mmap_output(struct perf_event *event,
 	mmap_event->event_id.header.size = size;
 }
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+static void perf_fix_fallback(u32 *flags, char *name)
+{
+	*flags &= ~MAP_HUGETLB;
+	name[strlen(name) - sizeof("(deleted)")] = '\0';
+}
+#endif
+
 static void perf_event_mmap_event(struct perf_mmap_event *mmap_event)
 {
 	struct vm_area_struct *vma = mmap_event->vma;
@@ -7554,6 +7562,10 @@ static void perf_event_mmap_event(struct perf_mmap_event *mmap_event)
 	strlcpy(tmp, name, sizeof(tmp));
 	name = tmp;
 got_name:
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+	if (vma->vm_flags & VM_EXEC_HUGEPAGES)
+		perf_fix_fallback(&flags, name);
+#endif
 	/*
 	 * Since our buffer works in 8 byte units we need to align our string
 	 * size to a multiple of 8. However, we must guarantee the tail end is
diff --git a/kernel/fork.c b/kernel/fork.c
index 843f5e525..3f8a4d710 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -572,6 +572,11 @@ static __latent_entropy int dup_mmap(struct mm_struct *mm,
 			i_mmap_unlock_write(mapping);
 		}
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+		if (is_vm_exec_hugepages(tmp) && tmp->vm_real_file)
+			get_file(tmp->vm_real_file);
+#endif
+
 		/*
 		 * Clear hugetlb-related page reserves for children. This only
 		 * affects MAP_PRIVATE mappings. Faults generated by the child
diff --git a/lib/Kconfig.euleros b/lib/Kconfig.euleros
index eb1145a0c..b3863ca96 100644
--- a/lib/Kconfig.euleros
+++ b/lib/Kconfig.euleros
@@ -354,4 +354,14 @@ config EULEROS_SOFT_AFFINITY
 	help
 	  The scheduler prefer a given a set of CPUs while scheduling a task,
 	  but using other available CPUs if the preferred set is all busy.
+
+config EULEROS_EXEC_HUGEPAGES
+	bool "use hugepages in exec"
+	default n
+	depends on HUGETLBFS && BINFMT_ELF
+	help
+	  This config allows elf executables and libraries marked by hugepageedit
+	  to be mapped with hugepages.
+	  Set exec_hugepages in cmdline to enable this features.
+
 endmenu
diff --git a/mm/hugetlb.c b/mm/hugetlb.c
index 4e273d523..32bc08737 100644
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@ -4854,6 +4854,9 @@ static int hugetlb_no_page(struct mm_struct *mm, struct vm_area_struct *vma,
 	spinlock_t *ptl;
 	unsigned long haddr = address & huge_page_mask(h);
 	bool new_page = false;
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+	loff_t off = haddr - vma->vm_start + (vma->vm_pgoff << PAGE_SHIFT);
+#endif
 
 	/*
 	 * Currently, we are forced to kill the process in the event the
@@ -4917,6 +4920,9 @@ static int hugetlb_no_page(struct mm_struct *mm, struct vm_area_struct *vma,
 			goto out;
 		}
 		clear_huge_page(page, address, pages_per_huge_page(h));
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+		read_real_file(page, vma, &off);
+#endif
 		__SetPageUptodate(page);
 		new_page = true;
 
diff --git a/mm/mmap.c b/mm/mmap.c
index 458be4fda..386c3ab5a 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -182,6 +182,10 @@ static struct vm_area_struct *remove_vma(struct vm_area_struct *vma)
 		vma->vm_ops->close(vma);
 	if (vma->vm_file)
 		fput(vma->vm_file);
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+	if (is_vm_exec_hugepages(vma) && vma->vm_real_file)
+		fput(vma->vm_real_file);
+#endif
 	mpol_put(vma_policy(vma));
 	vm_area_free(vma);
 	return next;
@@ -1545,6 +1549,10 @@ unsigned long do_mmap(struct file *file, unsigned long addr,
 			vm_flags |= VM_NORESERVE;
 	}
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+	if (flags & MAP_EXEC_HUGEPAGES)
+		vm_flags |= VM_EXEC_HUGEPAGES;
+#endif
 	addr = mmap_region(file, addr, len, vm_flags, pgoff, uf);
 	if (!IS_ERR_VALUE(addr) &&
 	    ((vm_flags & VM_LOCKED) ||
@@ -1553,6 +1561,56 @@ unsigned long do_mmap(struct file *file, unsigned long addr,
 	return addr;
 }
 
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+/*
+ * vm_mmap_hugepage() - file map with hugepage, used by exec hugepages
+ *
+ * We don't want to change vm_mmap, so we need to set vm_real_file
+ * and pgoff after vm_mmap.
+ * Name of the hugetlb file is changed to real file name to fix perf
+ * event infomation.
+ */
+unsigned long vm_mmap_hugepage(struct file *file, unsigned long addr,
+		unsigned long len, unsigned long prot,
+		unsigned long flag, unsigned long off)
+{
+	static char path[PATH_MAX];
+	unsigned long ret;
+	struct file *h_file;
+	struct user_struct *user = NULL;
+	struct vm_area_struct *vma;
+	char *name;
+	struct mm_struct *mm = current->mm;
+	unsigned long file_size;
+
+	if (len & (HPAGE_SIZE - 1))
+		return -EINVAL;
+
+	/* similar to the handling of MAP_HUGETLB in ksys_mmap_pgoff*/
+	name = file ? file_path(file, path, PATH_MAX) + 1 : HUGETLB_ANON_FILE;
+	file_size = ALIGN(off, HPAGE_SIZE) + len;
+	h_file = hugetlb_file_setup(name, file_size, VM_NORESERVE, &user,
+			HUGETLB_ANONHUGE_INODE, 0);
+	if (IS_ERR(file))
+		return PTR_ERR(file);
+	flag |= MAP_NORESERVE | MAP_EXEC_HUGEPAGES;
+	ret = vm_mmap(h_file, addr, len, prot, flag, 0);
+	fput(h_file);
+	if (IS_ERR_VALUE(ret))
+		return ret;
+
+	if (!file)
+		return ret;
+	if (down_write_killable(&mm->mmap_sem))
+		return -EINTR;
+	vma = find_vma(current->mm, ret);
+	vma->vm_real_file = get_file(file);
+	vma->vm_pgoff = off >> PAGE_SHIFT;
+	up_write(&mm->mmap_sem);
+	return ret;
+}
+#endif
+
 unsigned long ksys_mmap_pgoff(unsigned long addr, unsigned long len,
 			      unsigned long prot, unsigned long flags,
 			      unsigned long fd, unsigned long pgoff)
diff --git a/mm/util.c b/mm/util.c
index d44f5e95b..7c946c417 100644
--- a/mm/util.c
+++ b/mm/util.c
@@ -777,3 +777,21 @@ int get_cmdline(struct task_struct *task, char *buffer, int buflen)
 out:
 	return res;
 }
+
+#ifdef CONFIG_EULEROS_EXEC_HUGEPAGES
+void read_real_file(struct page *page, struct vm_area_struct *vma, loff_t *off)
+{
+	void *kaddr;
+	unsigned long page_size = PageCompound(page) ?
+		HPAGE_SIZE : PAGE_SIZE;
+	unsigned long read_size = 0;
+
+	if (!is_vm_exec_hugepages(vma) || !vma->vm_real_file)
+		return;
+	kaddr = kmap(page);
+	read_size = kernel_read(vma->vm_real_file, kaddr, page_size, off);
+	kunmap(page);
+	if (read_size) {
+	}
+}
+#endif
-- 
2.27.0

